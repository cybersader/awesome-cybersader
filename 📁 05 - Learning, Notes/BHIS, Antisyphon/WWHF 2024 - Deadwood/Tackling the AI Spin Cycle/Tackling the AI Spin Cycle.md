---
aliases:
  - A Briefing - Tackling the AI Spin Cycle - Kelli Tarala
tags:
  - governance
  - risk-assessment
  - risk-management
  - NIST
publish: true
date created: Thursday, October 10th 2024, 11:55 am
date modified: Thursday, October 10th 2024, 12:33 pm
---

by Kelli Tarala.
AI Governance, Laws, and Tools

# AI and Hurricanes

- AI is unpredictable
- It's a black box that is nuanced 
- Prep is possible and recommended

# What is AI?

- AI is the dirty laundry for a lot of people
- We are throwing a lot of our problems at AI, but we need guardrails for this

# The AI Craze

- IAPP content is great around this
- Fears of AI
	- bias, unfairness
	- job loss
	- data breaches
	- surveillance
	- transparency
	- unpredictability
	- black box
	- sentience
	- self awareness
	- uncontrollable AI
	- existential threat
- Applying AI to high risk issues is irresponsible

# Why AI Systems are Different

- It's a tool that can be used as a powerful weapon with the ammunition being data.  It has incredible flexibility because we are in the modern era of knowledge work.
- We have to define risks around AI systems
- The data component of AI presents many dilemmas 

- There's no such thing as patching with AI.  Essentially, we have to "align" the AI.  This is called the alignment problem.  How do we know the AI is being training or implemented in the direction that we want when they are incredibly complex
- Socio-technical stickiness - technology works for humans and by humans, but that presents lots of issues - some humans do bad things - again...alignment problem

# AI Governance

- What is AI governance
	- Guardrails
	- Assess system's impacts
	- Combat misalignment via misinformation, utilitarian implementations/approaches by AI, and protecting data and privacy
- NIST AI Governance

## AI Governance Frameworks

- USA's executive order 14110
- EU AI act in 2024
- Unesco recommendations on ethics of AI
- OECD's AI principles

## Governance Commonalities

- Fairness
- Transparency
- Alignment
- Accountability
- Robustnes
- Safety
- Security

# AI Risk Management

- Frameworks exist:
	- NIST AI RMF 1.0
	- Follows along CSF 2.0
	- Read Appendix D - really helpful
- We can tack on the AI piece to existing structures and processes
- NIST AI Playbook
	- Documentation...please
- Long-Term Cybersecurity
	- Trustworthy AI - valid and reliable, resilient, transparent, explainable, and privacy-enabled
	- AI should have the least amount of data possible
- "A Taxonomy of Trustworthiness for AI"
- Mitre Atlas AI Incident & Risk Database
- NIST Crosswalks - they do this with AI regulations and documents too

# An Action Plan

- Create an AI working group at your company
	- People with personal projects can share this
- Define geographic scope
- Draft an AI AU policy for employees
	- People want to play with tools to help them.  We are in a new era, so it may be hard to know exactly how you will use them.
	- SANS put out a draft AU policy for AI
- Update your org's 3rd party RM policy
	- Do it as a part of your reviews of vendors
- Integrate a RM framework
	- Do crosswalks with AI ones
- Maintain policies for training and retraining
	- Training governance and security employees
- Consider ad-hoc training regarding necessary legal and regulatory considerations that may impact AI-related design, development, and deployment activities
	- This could be from 3rd parties too
	- Just have them read it too

# Resources

- IAPP 
- DataSociety
- MS RAI Impact Assessment Guide
- PMI org talk to ai prompt engineering
- Books
	- AI Snake Oil
	- HumbleBundle